\documentclass{style1}
\articletype{Research Article}
\usepackage{amsmath}
\usepackage{lineno}
\usepackage{makecell}
\date{ }

\begin{document}
\tableofcontents
\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%  body  %%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Recognition Algorithm}
The proposed gait recognition algorithm could be divided into four steps: (i) Image sequences pre-processing, (ii) Motion Silhouettes Image (MSI) generation, (iii) Principle components generation and (iv) Classification. Figure \ref{fig:1} shows a flow diagram of our proposed algorithm.

\begin{figure}[ht!]
\centering\includegraphics[width=13cm]{Fig1.pdf}
\caption{Flow diagram of gait recognition by using MSI}
\label{fig:1}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Preprocessing}
In our proposed gait recognition algorithm, silhouettes are the basis of the feature for recognition. To further eliminate the scaling effect, the silhouettes are extracted according to the size of bounding box and resize to a standard size (128 x 88 pixels). Figure \ref{fig:2} shows some examples of normalized silhouettes. 

\begin{figure}[ht!]
\centering\includegraphics[width=13cm]{Fig2.pdf}
\caption{Normalized silhouettes}
\label{fig:2}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Motion Silhouettes Image}
Motion Silhouettes Image (MSI) is a gray-level image where the pixel intensity is a function of the temporal history of motion of that pixel. The intensity of the MSI represents motion information. MSI embeds tome examples the critical spatial and q temporal information and it could be formulated by Equation \ref{eq:1}. Figure \ref{fig:3} shows of MSI.

\begin{equation}
MSI(x,y,t) = 
\begin{cases}
255 & \text{if } I(x,y,t) = 1\\
max(o,MSI(x,y,t-1) - 1) & \text{otherwise}
\end{cases}
\label{eq:1}
\end{equation}

where I is the silhouette image, t is the current time, x and y are the horizontal and vertical coordinates of the image respectively.

\begin{figure}[ht!]
\centering\includegraphics[width=13cm]{Fig3.pdf}
\caption{Examples of Motion Silhouette Image}
\label{fig:3}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Training and Transformation}
PCA is used for capturing the principle components of the input space. The purpose of using PCA is reducing the feature space to a subspace which maximizing the variance of classes. Suppose there are C classes for training, each class $c \in C$ has $N_c$ of q-dimensional MSI $m_{c,i}$ where i is the instance label. The total number of training samples is $N_{total} = N_1 + N_2 + ...+ N_c$. The average MSI of all samples $\mu \in R^q$ is defined as

\begin{equation}
\mu = \frac{1}{N_{total}} \sum \limits_{c \in C}  \sum \limits_{j = 1}^{Nc} m_{c,j}
\label{eq:2}
\end{equation}

and the covariance matrix $\Sigma_{MSI} is$ defined as

\begin{equation}
\Sigma_{MSI} = \frac{1}{N_{total}}\sum \limits_{c \in C}  \sum \limits_{j = 1}^{Nc} (m_{c,j} - \mu)(m_{c,j} - \mu)^T
\label{eq:3}
\end{equation}

A transformation matrix $W_{pca} = [w_1, w_2,..., w_3]$ is obtained where $w_1, w_2,..., w_3$ are the eigenvectors of the samples covariance matrix $\Sigma_{MSI}$ corresponding to p (p<q) largest eigenvalues. These eigenvectors are orthonormal to each other and span the eigenspace.
The original MSI $m_{c,j}$ is projected to points $p_{c,j}$ in p-dimensional eigenspace by using the transformation matrix $W_{pca}$

\begin{equation}
p_{c,i} = W_{pca}^T m_{i.j} = [w_1, w_2,..., w_3]^Tm_{i,j}
\label{eq:4}
\end{equation}

where $c \in C$ and $i = 1,2,...,N_c$
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Recognition}
Suppose an input image sequence be r(t), where $t=1,2,...,T$. MSI $m_r$ is generated by using (1). The MSI is projected into the eigenspace by 

\begin{equation}
z_r = [w_1, w_2,..., w_3]^Tm_{r}
\label{eq:5}
\end{equation}

The Euclidean distance E between the projected testing feature vector and the projected  training feature vector is calculated (6).

\begin{equation}
E(z_r, z_{c,i}) = \sqrt{(z_r - z_{c,i})^T(z_r - z_{c,i})}
\label{eq:5}
\end{equation}

where $z_r$ is the projected feature vector of testing MSI $m_r$ and $z_{c,i}$ is the projected feature vector of training MSI $m_{c,i}$. The calculated Euclidean distance E is used for classification by using the nearest neighbor (NN) classifier. The image sequence r(t) is classified as class c if the Euclidean distance E is the minimum among other training samples.
A Survey on Gait Recognition:
\begin{enumerate}
\item Data acquisition. The gait data can be acquired by camera, accelerometer, floor sensor, and radar. Different acquisition method outputs different gait data. 
\item Feature representation. Different gait data can be represented in different ways. For videobased gait data acquired by camera, model-based and model-free feature representations are the main techniques. For gait data collected using accelerometer, floor sensor, and radar, there may be a variety of features, extracted in the frequency, time, and space domains. 
\item Dimension reduction. Typically, features extracted from gait data cannot be directly used for classification because the dimensionality of features extracted from raw data in the feature representation step is higher than training data. Therefore, a dimension reduction technique is needed. Dimension reduction can be divided into two types, namely feature reduction and outliers removal. Feature reduction aims to delete non-important features, while outliers removal aims to remove bad quality signals.
\item Classification. Classification is the last phase of a gait recognition system, which identifies individuals. In this article, we mainly discussed seven kinds of classification algorithms, namely distance, correlation, machine learning, neural network, hidden Markov model, dynamic time wrapping, and Bayesian classification.
\end{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Improvement of recognition}
The use of forensic gait analysis could be improved by: 
\begin{itemize}
\item Scientific studies to expand knowledge on intra-and inter-subject gait feature variabilities and discriminative value and interdependency of measured or observed gait features, and clarify the collection and use of databases and likelihood estimation calculations.  
\item Scientific studies to compare strengths and limitations of model- and silhouette-based (partly-) automated gait recognition algorithms with observer-based methods, and evaluate whether and when they should be used complementary or individually.  
\item An international standard method with known accuracy, validity and reliability and proficiency tests for gait analysts.  
\item An international standard data collection method for gait feature databases, resulting in analogous (inter)national gait feature databases.  
\item (Inter)national guidelines for the admission of gait evidence in court.  
\end{itemize}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Recognition with Different Eigenvalues}
In this experiment, we used seven different percentages of accumulated variance of eigenvalues for evaluating the influence of the eigenvalues. The result is tabulated in Table 1. The result showed that the recognition rate is directly proportional to the number of eigenvectors. Again, the overall recognition rate by using (A) 90\% train and 10\% test is better than the others (B \& C).
\newpage
Table 1 –  Recognition rates with different eigenvalues

\begin{center}
\begin{tabular}{|c|c  |c  |c  |c  |c  |c  |c |} \hline 

  & 65\% & 70\% & 75\% & 80\% & 85\% & 90\% & 95\% \\ \hline  

\makecell{(A)\\90\%\\train,\\10\%\\test} &
\makecell{(i)\\77.11\%\\(ii)\\87.55\%\\(iii)\\93.98\%} &
\makecell{(i)\\81.53\%\\(ii)\\90.36\%\\(iii)\\94.38\%} &
\makecell{(i)\\83.13\%\\(ii)\\92.37\%\\(iii)\\95.98\%} & 
\makecell{(i)\\85.54\%\\(ii)\\93.57\%\\(iii)\\95.98\%} &
\makecell{(i)\\87.15\%\\(ii)\\95.58\%\\(iii)\\95.98\%} &
\makecell{(i)\\86.75\%\\(ii)\\94.78\%\\(iii)\\95.98\%} &
\makecell{(i)\\87.15\%\\(ii)\\95.18\%\\(iii)\\95.98\%}  \\ \hline 

\makecell{(B)\\75\%\\train,\\15\%\\test} &
\makecell{(i)\\74.51\%\\(ii)\\88.77\%\\(iii)\\92.51\%} &
\makecell{(i)\\79.32\%\\(ii)\\90.37\%\\(iii)\\93.94\%} &
\makecell{(i)\\81.64\%\\(ii)\\91.27\%\\(iii)\\94.83\%} &
\makecell{(i)\\83.42\%\\(ii)\\92.51\%\\(iii)\\94.83\%} &
\makecell{(i)\\85.03\%\\(ii)\\93.76\%\\(iii)\\95.01\%} &
\makecell{(i)\\84.14\%\\(ii)\\93.58\%\\(iii)\\95.19\%} &
\makecell{(i)\\84.85\%\\(ii)\\93.76\%\\(iii)\\95.37\%} \\ \hline 

\makecell{(C)\\50\%\\train,\\50\%\\test} &
\makecell{(i)\\71.51\%\\(ii)\\87.82\%\\(iii)\\91.75\%} &
\makecell{(i)\\76.76\%\\(ii)\\89.32\%\\(iii)\\92.88\%} &
\makecell{(i)\\79.19\%\\(ii)\\90.91\%\\(iii)\\94.38\%} &
\makecell{(i)\\80.79\%\\(ii)\\91.47\%\\(iii)\\94.56\%} &
\makecell{(i)\\81.82\%\\(ii)\\92.22\%\\(iii)\\94.75\%} &
\makecell{(i)\\81.91\%\\(ii)\\92.41\%\\(iii)\\94.56\%} &
\makecell{(i)\\82.10\%\\(ii)\\92.31\%\\(iii)\\94.94\%} \\ \hline



\end{tabular}
\end{center}
(i) – Top 1, (ii) – Top 5, (iii) – Top 10






\end{document}